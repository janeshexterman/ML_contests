{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" class=\"alert alert-info\" role=\"alert\">\n",
    "    <h1>\n",
    "        Sibur Challenge 2020\n",
    "        <br>\n",
    "        <small class=\"text-muted\">онлайн-чемпионат по анализу данных</small>\n",
    "    </h1>\n",
    "</div>\n",
    "<div align=\"right\" class=\"alert alert-info\" role=\"alert\">\n",
    "    <h3>Евгения Хомякова (в составе команды \"+-3сигмы\"), 2020/12</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сопоставление названий\n",
    "\n",
    "При поиске новых клиентов СИБУРу приходится обрабатывать информацию о миллионах новых компаний из различных источников. Названия компаний при этом могут иметь разное написание, содержать сокращения или ошибки, быть аффилированными с компаниями, уже известными СИБУРу.\n",
    "\n",
    "Для более эффективной обработки информации о потенциальных клиентах, СИБУРу необходимо знать, связаны ли два названия (т.е. принадлежат одной компании или аффилированным компаниям).\n",
    "\n",
    "В этом случае СИБУР сможет использовать уже известную информацию о самой компании или об аффилированных компаниях, не дублировать обращения в компанию или не тратить время на нерелевантные компании или дочерние компании конкурентов.\n",
    "\n",
    "Тренировочная выборка содержит пары названий из разных источников (в том числе, пользовательских) и разметку.\n",
    "\n",
    "Разметка получена частично вручную, частично - алгоритмически. Кроме того, разметка может содержать ошибки. Вам предстоит построить бинарную модель, предсказывающую, являются ли два названия связанными. Метрика, используемая в данной задаче - F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", 'This pattern has match groups')\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pycountry\n",
    "\n",
    "from transliterate import translit\n",
    "\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()\n",
    "\n",
    "import textdistance as td\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\", index_col=\"pair_id\")\n",
    "test = pd.read_csv(\"test.csv\", index_col=\"pair_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv(\"train.csv\", index_col=\"pair_id\")\n",
    "test_raw = pd.read_csv(\"test.csv\", index_col=\"pair_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_1</th>\n",
       "      <th>name_2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iko Industries Ltd.</td>\n",
       "      <td>Enormous Industrial Trade Pvt., Ltd.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apcotex Industries Ltd.</td>\n",
       "      <td>Technocraft Industries (India) Ltd.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rishichem Distributors Pvt., Ltd.</td>\n",
       "      <td>Dsa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Powermax Rubber Factory</td>\n",
       "      <td>Co. One</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tress A/S</td>\n",
       "      <td>Longyou Industries Park Zhejiang</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    name_1  \\\n",
       "pair_id                                      \n",
       "1                      Iko Industries Ltd.   \n",
       "2                  Apcotex Industries Ltd.   \n",
       "3        Rishichem Distributors Pvt., Ltd.   \n",
       "4                  Powermax Rubber Factory   \n",
       "5                                Tress A/S   \n",
       "\n",
       "                                       name_2  is_duplicate  \n",
       "pair_id                                                      \n",
       "1        Enormous Industrial Trade Pvt., Ltd.             0  \n",
       "2         Technocraft Industries (India) Ltd.             0  \n",
       "3                                         Dsa             0  \n",
       "4                                     Co. One             0  \n",
       "5            Longyou Industries Park Zhejiang             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 497819 entries, 1 to 497819\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   name_1        497819 non-null  object\n",
      " 1   name_2        497819 non-null  object\n",
      " 2   is_duplicate  497819 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 85.0 MB\n"
     ]
    }
   ],
   "source": [
    "train.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_1</th>\n",
       "      <th>name_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun Blinds Decoration Inc.</td>\n",
       "      <td>Indl De Cuautitlan Sa Cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eih Ltd.</td>\n",
       "      <td>Dongguan Wei Shi Plastic Product Co., Ltd.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jsh Ltd. (Hk)</td>\n",
       "      <td>Arab Shipbuilding And Repair Yard C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Better Industrial Ltd.</td>\n",
       "      <td>Farmacap Industria E Comercio Ltda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Equipos Inoxidables Del Norte Sa De Cv</td>\n",
       "      <td>Bel Inc.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name_1  \\\n",
       "pair_id                                           \n",
       "1                    Sun Blinds Decoration Inc.   \n",
       "2                                      Eih Ltd.   \n",
       "3                                 Jsh Ltd. (Hk)   \n",
       "4                        Better Industrial Ltd.   \n",
       "5        Equipos Inoxidables Del Norte Sa De Cv   \n",
       "\n",
       "                                             name_2  \n",
       "pair_id                                              \n",
       "1                          Indl De Cuautitlan Sa Cv  \n",
       "2        Dongguan Wei Shi Plastic Product Co., Ltd.  \n",
       "3               Arab Shipbuilding And Repair Yard C  \n",
       "4                Farmacap Industria E Comercio Ltda  \n",
       "5                                          Bel Inc.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 213249 entries, 1 to 213249\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   name_1  213249 non-null  object\n",
      " 1   name_2  213249 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 34.8 MB\n"
     ]
    }
   ],
   "source": [
    "test.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Статистика таргета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    494161\n",
       "1      3658\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.is_duplicate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_1</th>\n",
       "      <th>name_2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121197</th>\n",
       "      <td>Bridgestone Firestone Do Brasil</td>\n",
       "      <td>Bridgestone International Group</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432422</th>\n",
       "      <td>Soprema Iberia</td>\n",
       "      <td>Soprema Iberia S.L.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16641</th>\n",
       "      <td>Bridgestone Ncr</td>\n",
       "      <td>Bridgestone (China) Research And Development C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116906</th>\n",
       "      <td>Michelin Siam Co., Ltd.</td>\n",
       "      <td>Sociedade Michelin De Participacoes Indust E C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36011</th>\n",
       "      <td>Michelin India Technology Center Llp</td>\n",
       "      <td>Michelin Siam Co., Ltd.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118899</th>\n",
       "      <td>Bridgestone Firestone De Mexico Sa De Cv</td>\n",
       "      <td>Bridgestone Ncr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441150</th>\n",
       "      <td>Bridgestone Firestone Venezolana C</td>\n",
       "      <td>Bridgestone Tire Co.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36565</th>\n",
       "      <td>Exxonmobil Chemical Americas 22777 Springwoods...</td>\n",
       "      <td>Exxonmobil Chemical Americas On</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176621</th>\n",
       "      <td>Trinseo Europe Gmb H Trade Register 20162359 T...</td>\n",
       "      <td>Trinseo Europe Gmb H Trade Register 20162359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231328</th>\n",
       "      <td>Bridgestone India Pvt., Ltd.</td>\n",
       "      <td>Bridgestone (Huizhou) Tire Co., Ltd.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name_1  \\\n",
       "pair_id                                                      \n",
       "121197                     Bridgestone Firestone Do Brasil   \n",
       "432422                                      Soprema Iberia   \n",
       "16641                                      Bridgestone Ncr   \n",
       "116906                             Michelin Siam Co., Ltd.   \n",
       "36011                 Michelin India Technology Center Llp   \n",
       "118899            Bridgestone Firestone De Mexico Sa De Cv   \n",
       "441150                  Bridgestone Firestone Venezolana C   \n",
       "36565    Exxonmobil Chemical Americas 22777 Springwoods...   \n",
       "176621   Trinseo Europe Gmb H Trade Register 20162359 T...   \n",
       "231328                        Bridgestone India Pvt., Ltd.   \n",
       "\n",
       "                                                    name_2  is_duplicate  \n",
       "pair_id                                                                   \n",
       "121197                     Bridgestone International Group             1  \n",
       "432422                                 Soprema Iberia S.L.             1  \n",
       "16641    Bridgestone (China) Research And Development C...             1  \n",
       "116906   Sociedade Michelin De Participacoes Indust E C...             1  \n",
       "36011                              Michelin Siam Co., Ltd.             1  \n",
       "118899                                     Bridgestone Ncr             1  \n",
       "441150                                Bridgestone Tire Co.             1  \n",
       "36565                      Exxonmobil Chemical Americas On             1  \n",
       "176621        Trinseo Europe Gmb H Trade Register 20162359             1  \n",
       "231328                Bridgestone (Huizhou) Tire Co., Ltd.             1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.is_duplicate==1].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_1</th>\n",
       "      <th>name_2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224453</th>\n",
       "      <td>Sant Rubbers Ltd.</td>\n",
       "      <td>St.Marys Rubbers Pvt., Ltd.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318777</th>\n",
       "      <td>BAL TABAN</td>\n",
       "      <td>BITOUMINA SA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445537</th>\n",
       "      <td>A S International</td>\n",
       "      <td>All Ways Forwarding International Inc.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299487</th>\n",
       "      <td>Sheikh Imp. &amp; Exp.</td>\n",
       "      <td>Xiamen Gulong Imp. &amp; Exp.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474144</th>\n",
       "      <td>Al Amal Co.</td>\n",
       "      <td>Anti Malaria Campaign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439498</th>\n",
       "      <td>Cashbasisenterprises Llc</td>\n",
       "      <td>Eterna S.A.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12595</th>\n",
       "      <td>J &amp; K Industries</td>\n",
       "      <td>Sun Pharmaceutical Industries Ltd.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17420</th>\n",
       "      <td>Nad International S A De C V</td>\n",
       "      <td>Global Agri Trade Corp.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68961</th>\n",
       "      <td>Kunshan Daou New Materials Co., Ltd.</td>\n",
       "      <td>Mactex Corporation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448125</th>\n",
       "      <td>Kbr India Corporation</td>\n",
       "      <td>Vivo Mobile India Pvt., Ltd.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       name_1  \\\n",
       "pair_id                                         \n",
       "224453                      Sant Rubbers Ltd.   \n",
       "318777                              BAL TABAN   \n",
       "445537                      A S International   \n",
       "299487                     Sheikh Imp. & Exp.   \n",
       "474144                            Al Amal Co.   \n",
       "439498               Cashbasisenterprises Llc   \n",
       "12595                        J & K Industries   \n",
       "17420            Nad International S A De C V   \n",
       "68961    Kunshan Daou New Materials Co., Ltd.   \n",
       "448125                  Kbr India Corporation   \n",
       "\n",
       "                                         name_2  is_duplicate  \n",
       "pair_id                                                        \n",
       "224453              St.Marys Rubbers Pvt., Ltd.             0  \n",
       "318777                             BITOUMINA SA             0  \n",
       "445537   All Ways Forwarding International Inc.             0  \n",
       "299487                Xiamen Gulong Imp. & Exp.             0  \n",
       "474144                    Anti Malaria Campaign             0  \n",
       "439498                              Eterna S.A.             0  \n",
       "12595        Sun Pharmaceutical Industries Ltd.             0  \n",
       "17420                   Global Agri Trade Corp.             0  \n",
       "68961                        Mactex Corporation             0  \n",
       "448125             Vivo Mobile India Pvt., Ltd.             0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.is_duplicate==0].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# убираем неодинарные пробелы и пробелы в начале и конце строк\n",
    "def clean_spaces():\n",
    "    for df in [train, test]:\n",
    "        for name in ['name_1', 'name_2']:\n",
    "            df[name] = df[name].str.replace('\\s+', ' ', regex=True)\n",
    "            df[name] = df[name].str.strip()\n",
    "            df[name] = df[name].str.lstrip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Очистка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Убираем аномалии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нижний регистр\n",
    "for df in [train, test]:\n",
    "    for name in ['name_1', 'name_2']:\n",
    "        df[name] = df[name].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_1</th>\n",
       "      <th>name_2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201595</th>\n",
       "      <td>primeur ltd.</td>\n",
       "      <td>pt lawe adyaprima</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183137</th>\n",
       "      <td>co. one</td>\n",
       "      <td>azam enterprises</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58917</th>\n",
       "      <td>n j international inc.</td>\n",
       "      <td>c &amp; t logistics agente de carga e transporte ltda</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107321</th>\n",
       "      <td>infinite cr strips industries ltd.</td>\n",
       "      <td>aspire industries</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297758</th>\n",
       "      <td>sam international</td>\n",
       "      <td>tropic seafood</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153231</th>\n",
       "      <td>black rose industries ltd.</td>\n",
       "      <td>indian cork industries</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189407</th>\n",
       "      <td>radix usa co.</td>\n",
       "      <td>rankin usa inc.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63027</th>\n",
       "      <td>a.l.</td>\n",
       "      <td>mach 1 global services</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423770</th>\n",
       "      <td>ilg</td>\n",
       "      <td>mercantil s a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487614</th>\n",
       "      <td>bj's wholesale club inc.</td>\n",
       "      <td>sho international</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427398</th>\n",
       "      <td>airboss rubber compounding</td>\n",
       "      <td>dh compounding</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173653</th>\n",
       "      <td>winwell logistics inc.</td>\n",
       "      <td>shanghai zelin logistics co., ltd.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493318</th>\n",
       "      <td>malhotra rubbers ltd.</td>\n",
       "      <td>osaka rubber pvt., ltd.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319241</th>\n",
       "      <td>stigall sales inc.</td>\n",
       "      <td>asa international</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140833</th>\n",
       "      <td>cruman fast private ltd.</td>\n",
       "      <td>ibm india private ltd.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     name_1  \\\n",
       "pair_id                                       \n",
       "201595                         primeur ltd.   \n",
       "183137                              co. one   \n",
       "58917                n j international inc.   \n",
       "107321   infinite cr strips industries ltd.   \n",
       "297758                    sam international   \n",
       "153231           black rose industries ltd.   \n",
       "189407                        radix usa co.   \n",
       "63027                                  a.l.   \n",
       "423770                                  ilg   \n",
       "487614             bj's wholesale club inc.   \n",
       "427398           airboss rubber compounding   \n",
       "173653               winwell logistics inc.   \n",
       "493318                malhotra rubbers ltd.   \n",
       "319241                   stigall sales inc.   \n",
       "140833             cruman fast private ltd.   \n",
       "\n",
       "                                                    name_2  is_duplicate  \n",
       "pair_id                                                                   \n",
       "201595                                   pt lawe adyaprima             0  \n",
       "183137                                    azam enterprises             0  \n",
       "58917    c & t logistics agente de carga e transporte ltda             0  \n",
       "107321                                   aspire industries             0  \n",
       "297758                                      tropic seafood             0  \n",
       "153231                              indian cork industries             0  \n",
       "189407                                     rankin usa inc.             0  \n",
       "63027                               mach 1 global services             0  \n",
       "423770                                       mercantil s a             0  \n",
       "487614                                   sho international             0  \n",
       "427398                                      dh compounding             0  \n",
       "173653                  shanghai zelin logistics co., ltd.             0  \n",
       "493318                             osaka rubber pvt., ltd.             0  \n",
       "319241                                   asa international             0  \n",
       "140833                              ibm india private ltd.             0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = [\n",
    "    # убрать китайское и арабское\n",
    "    '[\\u4E00-\\u9FFF]+|[\\u0621-\\u064A]+|[\\u0627-\\u064a]+',\n",
    "    # биржевые идентификаторы\n",
    "    '\\(?tse:\\d+\\)?', '\\(?nyse:.+\\)?', '\\(?nasdaq.+\\)?', '\\(?bse:\\d+\\)?',\n",
    "    #\n",
    "    'tax\\s?id\\s?\\d+',\n",
    "    # убрать кавычки, апострофы, запятые, звездочки, скобки\n",
    "    ',',\n",
    "    '/',\n",
    "    '\\.',\n",
    "    '`','`s',\n",
    "    '\\*',\n",
    "    '\\+',\n",
    "    '\\[', '\\]',\n",
    "    '\\(.*\\)',\n",
    "    '#',\n",
    "    ':',\n",
    "    '\"',\n",
    "    '\\?',\n",
    "    \"'s\",\n",
    "    \"'\",\n",
    "    '-',\n",
    "    '«', '»',\n",
    "    '&',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:28<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for a in tqdm(anomalies):\n",
    "    for df in [train, test]:\n",
    "        df['name_1'] = df['name_1'].str.replace(a, ' ', n=-1, regex=True)\n",
    "        df['name_2'] = df['name_2'].str.replace(a, ' ', n=-1, regex=True)\n",
    "clean_spaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# опечатки некоторые исправим\n",
    "for df in [train, test]:\n",
    "    for series_name in ['name_1', 'name_2']:\n",
    "        df[series_name] = df[series_name].str.replace(r'g\\s?m\\s?b\\s?h', 'gmbh', regex=True)\n",
    "        df[series_name] = df[series_name].str.replace('mexico', ' ', regex=True) #очень много где есть, мешает чистке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сложный случай с ё: в трейне она одна, но заменим везде \"ё\" ее на \"о\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_1</th>\n",
       "      <th>name_2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24723</th>\n",
       "      <td>dorken gmbh co kg</td>\n",
       "      <td>ооо дёркен</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name_1      name_2  is_duplicate\n",
       "pair_id                                             \n",
       "24723    dorken gmbh co kg  ооо дёркен             1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.name_1.str.contains('ё') | train.name_2.str.contains('ё')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А также другие символы с точечками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots_replace_dict = {\n",
    "    'ё': 'о',\n",
    "    \"é\": \"e\",\n",
    "    \"ę\": \"e\",\n",
    "    \"è\": \"e\",\n",
    "    \n",
    "    \"í\": \"i\",\n",
    "    \n",
    "    \"ú\": \"u\",\n",
    "    \"ü\": \"u\",\n",
    "    \"ű\": \"u\",\n",
    "    \n",
    "    \"ö\": \"o\",\n",
    "    \"ó\": \"o\",\n",
    "    \"õ\": \"o\",\n",
    "    \"ő\": \"o\",\n",
    "    \n",
    "    \"ä\": \"a\",\n",
    "    \"á\": \"a\",\n",
    "    \"ä\": \"a\",\n",
    "    \"ã\": \"a\", \n",
    "    \"ç\": \"c\",\n",
    "    \"ł\": \"l\",\n",
    "    \n",
    "    \"ñ\": \"n\",\n",
    "    \"ş\": \"s\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:15<00:00,  1.27it/s]\n"
     ]
    }
   ],
   "source": [
    "for key, value in tqdm(dots_replace_dict.items()):\n",
    "    for df in [train, test]:\n",
    "        df['name_1'] = df['name_1'].str.replace(key, value, regex=True)\n",
    "        df['name_2'] = df['name_2'].str.replace(key, value, regex=True)\n",
    "clean_spaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name_1          dorken gmbh co kg\n",
       "name_2                 ооо доркен\n",
       "is_duplicate                    1\n",
       "Name: 24723, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[24723]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3586"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка полных дубликатов 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['full_duplicate'] = train.apply(lambda x: set(x.name_1.split()) == set(x.name_2.split()), axis=1).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train.full_duplicate == 1) & (train.is_duplicate == 0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем одинаковый порядок слов\n",
    "train.loc[train.full_duplicate == 1, 'name_1'] = train.loc[train.full_duplicate == 1, 'name_2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверим полные дубликаты в тесте\n",
    "test['full_duplicate'] = test.apply(lambda x: set(x.name_1.split()) == set(x.name_2.split()), axis=1).astype('int')\n",
    "# сделаем одинаковый порядок слов\n",
    "test.loc[test.full_duplicate == 1, 'name_1'] = test.loc[test.full_duplicate == 1, 'name_2'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отсечем от первого имени одно слово с конца:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del1_word_n1(row):\n",
    "    n1 = row.name_1.split()\n",
    "    n2 = row.name_2.split()\n",
    "    if len(n1) > 1:\n",
    "        return set(n1[:-1]) == set(n2)\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['full_duplicate_1'] = train.apply(del1_word_n1, axis=1).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train.full_duplicate_1 == 1) & (train.is_duplicate == 0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем одинаковый порядок слов\n",
    "train.loc[train.full_duplicate_1 == 1, 'name_1'] = train.loc[train.full_duplicate_1 == 1, 'name_2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отметим такие же дубликаты в тесте\n",
    "test['full_duplicate_1'] = test.apply(del1_word_n1, axis=1).astype('int')\n",
    "# сделаем одинаковый порядок слов\n",
    "test.loc[test.full_duplicate_1 == 1, 'name_1'] = test.loc[test.full_duplicate_1 == 1, 'name_2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 4)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['full_duplicate_1'] == 1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То же самое, но от второго названия уберем одно слово:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del1_word_n2(row):\n",
    "    n1 = row.name_1.split()\n",
    "    n2 = row.name_2.split()\n",
    "    if len(n1) > 1:\n",
    "        return set(n1) == set(n2[:-1])\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['full_duplicate_2'] = train.apply(del1_word_n2, axis=1).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 6)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train.full_duplicate_2 == 1) & (train.is_duplicate == 0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем одинаковый порядок слов\n",
    "train.loc[train.full_duplicate_2 == 1, 'name_2'] = train.loc[train.full_duplicate_2 == 1, 'name_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим эти столбцы\n",
    "train['label'] = train[['full_duplicate','full_duplicate_1','full_duplicate_2']].max(axis=1)\n",
    "train = train.drop(['full_duplicate', 'full_duplicate_1', 'full_duplicate_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отметим такие же дубликаты в тесте\n",
    "test['full_duplicate_2'] = test.apply(del1_word_n2, axis=1).astype('int')\n",
    "# сделаем одинаковый порядок слов\n",
    "test.loc[test.full_duplicate_2 == 1, 'name_2'] = test.loc[test.full_duplicate_2 == 1, 'name_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в тесте сделаем столбец разметки на основе сравнения\n",
    "test['label'] = test[['full_duplicate','full_duplicate_1','full_duplicate_2']].max(axis=1)\n",
    "test = test.drop(['full_duplicate', 'full_duplicate_1', 'full_duplicate_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 4)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train.label == 1) & (train.is_duplicate == 0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test.label==1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Продолжаем чистку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые названия выглядят как 'буква( буква) буква':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_1</th>\n",
       "      <th>name_2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>beijing zhongyi rongda tech trading co ltd</td>\n",
       "      <td>n j international inc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>r i intl</td>\n",
       "      <td>rass mfg india pvt ltd</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>warehouse jonesboro</td>\n",
       "      <td>s k international</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>h r international</td>\n",
       "      <td>a r</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>s r international</td>\n",
       "      <td>cala trading group s de r l de c v</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497761</th>\n",
       "      <td>s r international</td>\n",
       "      <td>peliculas utiles sa de cv</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497796</th>\n",
       "      <td>mitsui chemicals india private ltd</td>\n",
       "      <td>h r international</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497797</th>\n",
       "      <td>oec freight inc</td>\n",
       "      <td>s r international</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497807</th>\n",
       "      <td>savita polymers</td>\n",
       "      <td>t a corporation pvt ltd</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497809</th>\n",
       "      <td>computime electric co ltd</td>\n",
       "      <td>a s international</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54594 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             name_1  \\\n",
       "pair_id                                               \n",
       "10       beijing zhongyi rongda tech trading co ltd   \n",
       "11                                         r i intl   \n",
       "15                              warehouse jonesboro   \n",
       "25                                h r international   \n",
       "26                                s r international   \n",
       "...                                             ...   \n",
       "497761                            s r international   \n",
       "497796           mitsui chemicals india private ltd   \n",
       "497797                              oec freight inc   \n",
       "497807                              savita polymers   \n",
       "497809                    computime electric co ltd   \n",
       "\n",
       "                                     name_2  is_duplicate  label  \n",
       "pair_id                                                           \n",
       "10                    n j international inc             0      0  \n",
       "11                   rass mfg india pvt ltd             0      0  \n",
       "15                        s k international             0      0  \n",
       "25                                      a r             0      0  \n",
       "26       cala trading group s de r l de c v             0      0  \n",
       "...                                     ...           ...    ...  \n",
       "497761            peliculas utiles sa de cv             0      0  \n",
       "497796                    h r international             0      0  \n",
       "497797                    s r international             0      0  \n",
       "497807              t a corporation pvt ltd             0      0  \n",
       "497809                    a s international             0      0  \n",
       "\n",
       "[54594 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = re.compile('^(\\w)\\s(\\w\\s)')\n",
    "train[(train.name_1.str.contains(reg) | train.name_2.str.contains(reg))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим их:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    df['name_1'] = df['name_1'].str.replace('^(\\w)\\s(\\w)\\s(\\w\\s?)', '\\\\1\\\\2\\\\3', regex=True)\n",
    "    df['name_2'] = df['name_2'].str.replace('^(\\w)\\s(\\w)\\s(\\w\\s?)', '\\\\1\\\\2\\\\3', regex=True)\n",
    "\n",
    "    df['name_1'] = df['name_1'].str.replace('^(\\w)\\s(\\w\\s?)', '\\\\1\\\\2', regex=True)\n",
    "    df['name_2'] = df['name_2'].str.replace('^(\\w)\\s(\\w\\s?)', '\\\\1\\\\2', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удаление legal entities\n",
    "\n",
    "https://en.wikipedia.org/wiki/List_of_legal_entity_types_by_country\n",
    "\n",
    "https://en.wikipedia.org/wiki/Private_limited_company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "enity_list = [\n",
    "    # все в этом словаре определено исключительно на трейне\n",
    "    'san\\s?v?e?\\s?tic', # +\n",
    "    'co',\n",
    "    #private limited company => ltd in UK and Commonwealth\n",
    "    'private ltd',\n",
    "    'private limited',\n",
    "    'pvt\\s?ltd',\n",
    "    'pvt',\n",
    "    'gmbh', #germany\n",
    "    'kft', #hungary\n",
    "    'pty\\s?l?t?d?', #australia\n",
    "    'l\\s?l\\s?c', #usa\n",
    "    'sp\\s?z\\s?o\\s?o', #poland\n",
    "    'pte\\s?l?t?d?', #singapore\n",
    "    'lda', #portugal\n",
    "    'pt', #indonesia\n",
    "    'p\\s?m\\s?e', 'w\\s?l\\s?l',\n",
    "    'ооо', #russia\n",
    "    'общество\\sс\\sогр\\S*\\sответ\\S*',\n",
    "    's\\s?r\\s?o', #slovakia/ceska_republika\n",
    "    'd\\s?o\\s?o', #west_europe\n",
    "    's\\s?i\\s?a', #latvia\n",
    "    '(e\\s?i\\s?r)?\\s?l\\s?t\\s?d\\s?a', #south_america\n",
    "    'e\\s?i\\s?r\\s?l', #south_america, #eirl\n",
    "    's\\s?[pac]\\s?r\\s?l', #belgium, france/africa\n",
    "    's\\s?a\\s?s', #sas\n",
    "    'a\\s?s', #turkey\n",
    "    '(rls)?\\s?s?\\s?de\\s?r\\s?l\\s?(de)?\\s?c\\s?v', #mexico (rls) (s) de rl de cv\n",
    "    's?\\s?de\\s?r\\s?l', #mexico\n",
    "    '(de)?\\s?s?s\\s?a de cv', #mexico\n",
    "    's\\s?a\\s?p\\s?i\\s?de\\s?c\\s?v', #mexico\n",
    "    \n",
    "    #public limited company => plc in UK and Commonwealth\n",
    "    'public ltd',\n",
    "    'p\\s?l\\s?c', #uk\n",
    "    's\\s?a\\d?\\s?de\\s?c\\s?v', #mexico + \n",
    "    's\\s?a',\n",
    "    'sociedad', 'anonima',\n",
    "    '[зо]?ао', #russia\n",
    "    'ag', #germany\n",
    "    's\\s?p\\s?a', #italy\n",
    "    \n",
    "    # если после всего этого останется ltd еще\n",
    "    'l\\s?t\\s?d',\n",
    "    'limited',\n",
    "    \n",
    "    'sti', 'l\\s?p', 's\\s?l\\s?u', 'c\\s?a', 'b\\s?v', 'n\\s?v',  'sp\\s?k?',\n",
    "    '(de)?\\s?c\\s?v',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [02:16<00:00,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for le in tqdm(enity_list):\n",
    "    le_reg = re.compile('(^|\\s+)'+le+'(\\s+|$)')\n",
    "    for df in [train, test]:\n",
    "        df['name_1'] = df['name_1'].str.replace(le_reg, ' ', regex=True)\n",
    "        df['name_2'] = df['name_2'].str.replace(le_reg, ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_spaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_1</th>\n",
       "      <th>name_2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>391449</th>\n",
       "      <td>diamond rubber products</td>\n",
       "      <td>rohit rubber corporation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477401</th>\n",
       "      <td>sto corp</td>\n",
       "      <td>jsw steel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478177</th>\n",
       "      <td>forte</td>\n",
       "      <td>huicheng foreign processing assembling service</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398654</th>\n",
       "      <td>pro rubber</td>\n",
       "      <td>polyhose india</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476310</th>\n",
       "      <td>xiamen gulong imp exp</td>\n",
       "      <td>lucky imp exp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name_1  \\\n",
       "pair_id                            \n",
       "391449   diamond rubber products   \n",
       "477401                  sto corp   \n",
       "478177                     forte   \n",
       "398654                pro rubber   \n",
       "476310     xiamen gulong imp exp   \n",
       "\n",
       "                                                 name_2  is_duplicate  label  \n",
       "pair_id                                                                       \n",
       "391449                         rohit rubber corporation             0      0  \n",
       "477401                                        jsw steel             0      0  \n",
       "478177   huicheng foreign processing assembling service             0      0  \n",
       "398654                                   polyhose india             0      0  \n",
       "476310                                    lucky imp exp             0      0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6554"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\n",
    "    'the', 'of', 'do', 'and', \"to\", 'e', 've', 'de',\n",
    "    'automotive',\n",
    "    'bank', \n",
    "    'chemicals?',\n",
    "    'company','corporation', 'corp', 'co', 'comerci\\S*', \"com\", 'city',\n",
    "    'distribution', \n",
    "    'equipment', 'exp', 'enterprise\\S*', 'electronic\\S*','engineering', \n",
    "    'global', 'general', 'group',\n",
    "    'imp', 'importadora', 'international', 'industr\\S*', 'inds', 'inc',\n",
    "    'kg',\n",
    "    'logistic\\S*', 'lojistik',\n",
    "    'mfg','material\\S*',\n",
    "    'plastic\\S*', 'products','polymer\\S*',\n",
    "    'rubber', 'ram',\n",
    "    \"supply\", \"systems\", 'solutions', 'sports', 'service\\S*', \"synthetic\", 'sociedad', 'shoes',\n",
    "    'textile', 'trad\\S*', 'technolog\\S*', 'tech',  \"transport\\S*\", 't[iy]re',\n",
    "    \"united\", \n",
    "    '\\w', #любая одиночная буква\n",
    "    'компания', 'филиал\\sкомпании', 'филиал', 'снг', 'рус',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [02:31<00:00,  2.37s/it]\n"
     ]
    }
   ],
   "source": [
    "for stop_word in tqdm(stop_words):\n",
    "    stop_word_reg = re.compile('(^|\\s+)'+stop_word+'(\\s+|$)')\n",
    "    for df in [train, test]:\n",
    "        for name in ['name_1', 'name_2']:\n",
    "            df[name] = df[name].str.replace(stop_word_reg, ' ', regex=True)\n",
    "clean_spaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9584"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Транслитерация русского"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian = re.compile(r'[А-Яа-я]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1829"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train.name_1.str.contains(russian) | train.name_2.str.contains(russian)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_1</th>\n",
       "      <th>name_2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>263705</th>\n",
       "      <td>soprema polska</td>\n",
       "      <td>химинвест нпф</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117913</th>\n",
       "      <td>garland</td>\n",
       "      <td>химинвест групп</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57839</th>\n",
       "      <td>goodyear</td>\n",
       "      <td>полимаркет</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97152</th>\n",
       "      <td>total bitumen</td>\n",
       "      <td>химинвест нпф</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200125</th>\n",
       "      <td>lanxess</td>\n",
       "      <td>химинвест нпф</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name_1           name_2  is_duplicate  label\n",
       "pair_id                                                      \n",
       "263705   soprema polska    химинвест нпф             0      0\n",
       "117913          garland  химинвест групп             0      0\n",
       "57839          goodyear       полимаркет             0      0\n",
       "97152     total bitumen    химинвест нпф             0      0\n",
       "200125          lanxess    химинвест нпф             0      0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.name_1.str.contains(russian) | train.name_2.str.contains(russian)].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сделаем транслитерацию на строках, содержащих русские слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train.loc[train.name_1.str.contains(russian) | train.name_2.str.contains(russian), 'name_1'] = train.loc[train.name_1.str.contains(russian) | train.name_2.str.contains(russian),\n",
    "                                                                                                         'name_1'].apply(lambda x: translit(x, \"ru\", reversed=True))\n",
    "train.loc[train.name_1.str.contains(russian) | train.name_2.str.contains(russian), 'name_2'] = train.loc[train.name_1.str.contains(russian) | train.name_2.str.contains(russian),\n",
    "                                                                                                         'name_2'].apply(lambda x: translit(x, \"ru\", reversed=True))\n",
    "test.loc[test.name_1.str.contains(russian) | test.name_2.str.contains(russian), 'name_1'] = test.loc[test.name_1.str.contains(russian) | test.name_2.str.contains(russian),\n",
    "                                                                                                       'name_1'].apply(lambda x: translit(x, \"ru\", reversed=True))\n",
    "test.loc[test.name_1.str.contains(russian) | test.name_2.str.contains(russian),'name_2'] = test.loc[test.name_1.str.contains(russian) | test.name_2.str.contains(russian),\n",
    "                                                                                                      'name_2'].apply(lambda x: translit(x, \"ru\", reversed=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train.name_1.str.contains(russian) | train.name_2.str.contains(russian)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name_1          dorken\n",
       "name_2          dorken\n",
       "is_duplicate         1\n",
       "label                0\n",
       "Name: 24723, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[24723]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При транслитерации могли произойти неоднозначные замены, поправим их:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['name_1'] = train['name_1'].str.replace('w', 'v', regex=True)\n",
    "train['name_2'] = train['name_2'].str.replace('w', 'v', regex=True)\n",
    "test['name_1'] = test['name_1'].str.replace('w', 'v', regex=True)\n",
    "test['name_2'] = test['name_2'].str.replace('w', 'v', regex=True)\n",
    "\n",
    "train['name_1'] = train['name_1'].str.replace('ks', 'x', regex=True)\n",
    "train['name_2'] = train['name_2'].str.replace('ks', 'x', regex=True)\n",
    "test['name_1'] = test['name_1'].str.replace('ks', 'x', regex=True)\n",
    "test['name_2'] = test['name_2'].str.replace('ks', 'x', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# убираем неодинарные пробелы и пробелы в начале и конце строк\n",
    "clean_spaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_1</th>\n",
       "      <th>name_2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>384287</th>\n",
       "      <td>shipco</td>\n",
       "      <td>stp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161271</th>\n",
       "      <td>amtrans</td>\n",
       "      <td>panalpina uruguay mundiales</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33511</th>\n",
       "      <td>robertson</td>\n",
       "      <td>okamoto shenzhen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390109</th>\n",
       "      <td>haosheng vina</td>\n",
       "      <td>acs</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367526</th>\n",
       "      <td>zaklad metalovy gemo</td>\n",
       "      <td>vainternational</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447554</th>\n",
       "      <td>greenchem</td>\n",
       "      <td>topfils</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50198</th>\n",
       "      <td>nimsetha</td>\n",
       "      <td>aspire</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181390</th>\n",
       "      <td>chasse sohn inh radecke</td>\n",
       "      <td>oldcastle building</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433114</th>\n",
       "      <td>caleres</td>\n",
       "      <td>sinfa cables</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287473</th>\n",
       "      <td>unified overseas goods vholesalers</td>\n",
       "      <td>eia</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     name_1                       name_2  \\\n",
       "pair_id                                                                    \n",
       "384287                               shipco                          stp   \n",
       "161271                              amtrans  panalpina uruguay mundiales   \n",
       "33511                             robertson             okamoto shenzhen   \n",
       "390109                        haosheng vina                          acs   \n",
       "367526                 zaklad metalovy gemo              vainternational   \n",
       "447554                            greenchem                      topfils   \n",
       "50198                              nimsetha                       aspire   \n",
       "181390              chasse sohn inh radecke           oldcastle building   \n",
       "433114                              caleres                 sinfa cables   \n",
       "287473   unified overseas goods vholesalers                          eia   \n",
       "\n",
       "         is_duplicate  label  \n",
       "pair_id                       \n",
       "384287              0      0  \n",
       "161271              0      0  \n",
       "33511               0      0  \n",
       "390109              0      0  \n",
       "367526              0      0  \n",
       "447554              0      0  \n",
       "50198               0      0  \n",
       "181390              0      0  \n",
       "433114              0      0  \n",
       "287473              0      0  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_1</th>\n",
       "      <th>name_2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231764</th>\n",
       "      <td>synthomer peachtree lenox bl bonded 7320 state...</td>\n",
       "      <td>synthomer srl</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210107</th>\n",
       "      <td>rompetrol</td>\n",
       "      <td>rompetrol rafinare</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444587</th>\n",
       "      <td>evonik cryo</td>\n",
       "      <td>evonik cyro mobile</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144631</th>\n",
       "      <td>arlanxeo</td>\n",
       "      <td>arlanxeo</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48161</th>\n",
       "      <td>arlanxeo usa</td>\n",
       "      <td>arlanxeo canada</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461222</th>\n",
       "      <td>shenzhen comlink</td>\n",
       "      <td>shenzhen comlink</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169771</th>\n",
       "      <td>vertikal' sport</td>\n",
       "      <td>vertikal' sport</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338104</th>\n",
       "      <td>asfaltos chova</td>\n",
       "      <td>asfaltos chova</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437848</th>\n",
       "      <td>bridgestone india</td>\n",
       "      <td>bridgestone brasil comenrcio</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307359</th>\n",
       "      <td>evonik degussa brasil</td>\n",
       "      <td>evonik india</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name_1  \\\n",
       "pair_id                                                      \n",
       "231764   synthomer peachtree lenox bl bonded 7320 state...   \n",
       "210107                                           rompetrol   \n",
       "444587                                         evonik cryo   \n",
       "144631                                            arlanxeo   \n",
       "48161                                         arlanxeo usa   \n",
       "461222                                    shenzhen comlink   \n",
       "169771                                     vertikal' sport   \n",
       "338104                                      asfaltos chova   \n",
       "437848                                   bridgestone india   \n",
       "307359                               evonik degussa brasil   \n",
       "\n",
       "                               name_2  is_duplicate  label  \n",
       "pair_id                                                     \n",
       "231764                  synthomer srl             1      0  \n",
       "210107             rompetrol rafinare             1      0  \n",
       "444587             evonik cyro mobile             1      0  \n",
       "144631                       arlanxeo             1      1  \n",
       "48161                 arlanxeo canada             1      0  \n",
       "461222               shenzhen comlink             1      0  \n",
       "169771                vertikal' sport             1      1  \n",
       "338104                 asfaltos chova             1      1  \n",
       "437848   bridgestone brasil comenrcio             1      0  \n",
       "307359                   evonik india             1      0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.query('is_duplicate == 1').sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удаление названий стран"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# есть имена стран на других языках\n",
    "for df in [train, test]:\n",
    "    for series_name in ['name_1', 'name_2']:\n",
    "        df[series_name] = df[series_name].str.replace('brasil', 'brazil')\n",
    "        df[series_name] = df[series_name].str.replace('czechy', 'czechia')\n",
    "        df[series_name] = df[series_name].str.replace('polska', 'poland')\n",
    "        df[series_name] = df[series_name].str.replace('mexic\\S*', 'mexico', regex=True)\n",
    "        df[series_name] = df[series_name].str.replace('deutschland', 'germany')\n",
    "        df[series_name] = df[series_name].str.replace('turk', 'turkey')\n",
    "        df[series_name] = df[series_name].str.replace('nederland', 'netherlands')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = [country.name.lower() for country in pycountry.countries] + ['usa?', 'uk', 'america\\S*',\n",
    "                                                                         'north', 'south',\n",
    "                                                                         'europe', 'asia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 256/256 [07:17<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for country in tqdm(countries):\n",
    "    country_reg = re.compile('(^|\\s+)'+country+'(\\s+|$)')\n",
    "    for df in [train, test]:\n",
    "        df['name_1'] = df['name_1'].str.replace(country_reg, ' ', regex=True)\n",
    "        df['name_2'] = df['name_2'].str.replace(country_reg, ' ', regex=True)\n",
    "clean_spaces()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Убираем названия городов"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# по-хорошему надо так\n",
    "from allcities import cities\n",
    "cities_list = ([city.name.lower() for city in cities.filter(country_code='US')] + \n",
    "               [city.name.lower() for city in cities.filter(country_code='RU')] +\n",
    "               [city.name.lower() for city in cities.filter(country_code='DE')] +\n",
    "               [city.name.lower() for city in cities.filter(country_code='CN')] +\n",
    "               [city.name.lower() for city in cities.filter(country_code='MX')] +\n",
    "               [city.name.lower() for city in cities.filter(country_code='IN')] +\n",
    "               [city.name.lower() for city in cities.filter(country_code='ES')] +\n",
    "               [city.name.lower() for city in cities.filter(country_code='IT')]\n",
    ")\n",
    "\n",
    "\n",
    "print(len(cities_list))\n",
    "print(cities_list[:10])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cities_list_new = []\n",
    "for city in cities_list:\n",
    "    city = city.replace('ā','a').replace('ū','u').replace('ī','i')\n",
    "    cities_list_new.append(city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Названия китайских провинций из википедии https://wikitravel.org/en/List_of_Chinese_provinces_and_regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_prov = ['Anhui', 'Fujian', 'Gansu', 'Guangdong', 'Guizhou','Hainan','Hebe',\n",
    "           'Heilongjiang','Henan','Hubei','Hunan','Jiangsu','Jiangxiv','Jilin',\n",
    "           'Liaoning','Qinghai','Shaanxi','Shanxi','Sichuan','Yunnan','Zhejiang',]\n",
    "ch_prov = [i.lower() for i in ch_prov]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "cities_list = ['shenzhen', 'shanghai', 'guangzhou', 'guangdong', 'huizhou', #эти названия есть в трейне\n",
    "               'shenyang', 'dongguan', 'qingdao', 'shenzhen', 'zhongshan',\n",
    "               'hangzhou', 'tianjin', 'zhuhai', 'xiamen', 'changshu', \"ningbo\", 'suzhou',\n",
    "               'uchkurgan' ] + ch_prov + ['hindustan', 'khawaja', 'jindal']\n",
    "print(len(cities_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7627"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['name_1'].str.contains('shanghai').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [00:56<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for city in tqdm(cities_list):\n",
    "    train['name_1'] = train['name_1'].str.replace(city, ' ')\n",
    "    train['name_2'] = train['name_2'].str.replace(city, ' ')\n",
    "    test['name_1'] = test['name_1'].str.replace(city, ' ')\n",
    "    test['name_2'] = test['name_2'].str.replace(city, ' ')\n",
    "clean_spaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['name_1'].str.contains('shanghai').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#удалим все цифры (которые отдельным \"словом\")\n",
    "for df in [train, test]:\n",
    "    for col_name in ['name_1', 'name_2']:\n",
    "        df[col_name] = df[col_name].str.replace('(^|\\s+)\\d+(\\s+|$)', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9057"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_clean.csv', index=True)\n",
    "test.to_csv('test_clean.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка полных дубликатов 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['full_duplicate'] = train.apply(lambda x: set(x.name_1.split()) == set(x.name_2.split()), axis=1).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321, 5)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train.full_duplicate == 1) & ((train.is_duplicate == 0) | (train.label == 0))].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем одинаковый порядок слов\n",
    "train.loc[train.full_duplicate == 1, 'name_1'] = train.loc[train.full_duplicate == 1, 'name_2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверим полные дубликаты в тесте\n",
    "test['full_duplicate'] = test.apply(lambda x: set(x.name_1.split()) == set(x.name_2.split()), axis=1).astype('int')\n",
    "# сделаем одинаковый порядок слов\n",
    "test.loc[test.full_duplicate == 1, 'name_1'] = test.loc[test.full_duplicate == 1, 'name_2'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отсечем от первого имени одно слово с конца:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['full_duplicate_1'] = train.apply(del1_word_n1, axis=1).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(370, 6)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train.full_duplicate_1 == 1) & ((train.is_duplicate == 0) | (train.label == 0))].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем одинаковый порядок слов\n",
    "train.loc[train.full_duplicate_1 == 1, 'name_1'] = train.loc[train.full_duplicate_1 == 1, 'name_2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отметим такие же дубликаты в тесте\n",
    "test['full_duplicate_1'] = test.apply(del1_word_n1, axis=1).astype('int')\n",
    "# сделаем одинаковый порядок слов\n",
    "test.loc[test.full_duplicate_1 == 1, 'name_1'] = test.loc[test.full_duplicate_1 == 1, 'name_2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251, 5)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['full_duplicate_1'] == 1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То же самое, но от второго названия уберем одно слово:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['full_duplicate_2'] = train.apply(del1_word_n2, axis=1).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69, 7)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train.full_duplicate_2 == 1) & ((train.is_duplicate == 0) | (train.label == 0))].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем одинаковый порядок слов\n",
    "train.loc[train.full_duplicate_2 == 1, 'name_2'] = train.loc[train.full_duplicate_2 == 1, 'name_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим эти столбцы\n",
    "train['label'] = train[['label', 'full_duplicate','full_duplicate_1','full_duplicate_2']].max(axis=1)\n",
    "train = train.drop(['full_duplicate', 'full_duplicate_1', 'full_duplicate_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отметим такие же дубликаты в тесте\n",
    "test['full_duplicate_2'] = test.apply(del1_word_n2, axis=1).astype('int')\n",
    "# сделаем одинаковый порядок слов\n",
    "test.loc[test.full_duplicate_2 == 1, 'name_2'] = test.loc[test.full_duplicate_2 == 1, 'name_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в тесте сделаем столбец разметки на основе сравнения\n",
    "test['label'] = test[['label','full_duplicate','full_duplicate_1','full_duplicate_2']].max(axis=1)\n",
    "test = test.drop(['full_duplicate', 'full_duplicate_1', 'full_duplicate_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 4)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train.label == 1) & (train.is_duplicate == 0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(859, 3)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test.label==1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка дубликатов первого слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_first_words(row):\n",
    "    s1 = row['name_1']\n",
    "    s2 = row['name_2']\n",
    "    try:\n",
    "        fw1 = s1.split()[0]\n",
    "    except Exception:\n",
    "        fw1 = s1\n",
    "    try:\n",
    "        fw2 = s2.split()[0]\n",
    "    except Exception:\n",
    "        fw2 = s2\n",
    "    return fw1 == fw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train['first_word_duplicate']  = train.apply(check_first_words, axis=1).astype(\"int\")\n",
    "test['first_word_duplicate']  = test.apply(check_first_words, axis=1).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_1</th>\n",
       "      <th>name_2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>label</th>\n",
       "      <th>first_word_duplicate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pair_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iko</td>\n",
       "      <td>enormous</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apcotex</td>\n",
       "      <td>technocraft</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rishichem distributors</td>\n",
       "      <td>dsa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>povermax factory</td>\n",
       "      <td>one</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tress</td>\n",
       "      <td>longyou park</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name_1        name_2  is_duplicate  label  \\\n",
       "pair_id                                                              \n",
       "1                           iko      enormous             0      0   \n",
       "2                       apcotex   technocraft             0      0   \n",
       "3        rishichem distributors           dsa             0      0   \n",
       "4              povermax factory           one             0      0   \n",
       "5                         tress  longyou park             0      0   \n",
       "\n",
       "         first_word_duplicate  \n",
       "pair_id                        \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  \n",
       "5                           0  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['label'] = train[['label', 'first_word_duplicate']].max(axis=1)\n",
    "train = train.drop(['first_word_duplicate'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2231, 4)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train.label == 1) & (train.is_duplicate == 0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label'] = test[['label', 'first_word_duplicate']].max(axis=1)\n",
    "test = test.drop(['first_word_duplicate'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2181, 3)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test.label==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"org_name_1\"] = train_raw[\"name_1\"]\n",
    "train[\"org_name_2\"] = train_raw[\"name_2\"]\n",
    "\n",
    "test[\"org_name_1\"] = test_raw[\"name_1\"]\n",
    "test[\"org_name_2\"] = test_raw[\"name_2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрики сходства строк"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояния"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textdistance\n",
    "td_names = [\n",
    "    \n",
    "    'mlipns', \n",
    "    'hamming',\n",
    "    'hamming_norm',\n",
    "    'levenshtein',\n",
    "    'levenshtein_norm',\n",
    "    'damerau_levenshtein',\n",
    "    'jaro_winkler',\n",
    "    'strcmp95',\n",
    "    'tanimoto',\n",
    "    'monge_elkan',\n",
    "    'lcsseq',\n",
    "    'lcsstr',\n",
    "     \n",
    "    'needleman_wunsch',\n",
    "    'needleman_wunsch_norm',\n",
    "    'gotoh',\n",
    "    'smith_waterman',\n",
    "    'smith_waterman_norm',\n",
    "    \n",
    "    'ratcliff_obershelp',\n",
    "   \n",
    "    'cosine', \n",
    "    'jaccard',\n",
    "    'sorensen'\n",
    "\n",
    "]\n",
    "\n",
    "td_methods = [\n",
    "    td.mlipns.normalized_similarity,\n",
    "    td.hamming.similarity,\n",
    "    td.hamming.normalized_similarity,\n",
    "    td.levenshtein.similarity,\n",
    "    td.levenshtein.normalized_similarity,\n",
    "    td.damerau_levenshtein.normalized_similarity,\n",
    "    td.jaro_winkler.normalized_similarity,\n",
    "    td.strcmp95.normalized_similarity,\n",
    "    td.tanimoto.normalized_similarity,\n",
    "    td.monge_elkan.normalized_similarity,\n",
    "    td.lcsseq.normalized_similarity,\n",
    "    td.lcsstr.normalized_similarity,\n",
    "    \n",
    "    td.needleman_wunsch.similarity,\n",
    "    td.needleman_wunsch.normalized_similarity,\n",
    "    td.gotoh.normalized_similarity,\n",
    "    td.smith_waterman.normalized_similarity,\n",
    "    \n",
    "    td.ratcliff_obershelp.similarity,\n",
    "    \n",
    "    td.cosine.similarity,\n",
    "    td.jaccard.similarity,\n",
    "    td.sorensen.similarity\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def td_distance_count(row, method, name):\n",
    "    n1, n2 = row['name_1'], row['name_2']\n",
    "    if n1 == \"\" and n2 == \"\":\n",
    "        n1, n2 = row['org_name_1'], row['org_name_2']\n",
    "    \n",
    "    if name in ['jaccard', 'sorensen']:\n",
    "        return method(n1.split(' '), n2.split(' '))\n",
    "    \n",
    "    return method(''.join(n1.split(' ')), ''.join(n2.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fuzz\n",
    "fuzz_names = [\n",
    "    'ratio',\n",
    "    'partial_ratio',\n",
    "    'token_sort_ratio',\n",
    "    'token_set_ratio'\n",
    "]\n",
    "\n",
    "fuzz_methods = [\n",
    "    fuzz.ratio,\n",
    "    fuzz.partial_ratio,\n",
    "    fuzz.token_sort_ratio,\n",
    "    fuzz.token_set_ratio\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzz_distance_count(row, method, name):\n",
    "    n1, n2 = row['name_1'], row['name_2']\n",
    "    if n1 == \"\" and n2 == \"\":\n",
    "        n1, n2 = row['org_name_1'], row['org_name_2']\n",
    "    \n",
    "    return method(''.join(n1.split(' ')), ''.join(n2.split(' ')))/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddf для ускорения apply\n",
    "train_ddf = dd.from_pandas(train, npartitions=4)\n",
    "test_ddf = dd.from_pandas(test, npartitions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlipns\n",
      "[########################################] | 100% Completed | 18.3s\n",
      "[########################################] | 100% Completed | 20.6s\n",
      "[########################################] | 100% Completed | 21.0s\n",
      "[########################################] | 100% Completed |  8.1s\n",
      "[########################################] | 100% Completed |  8.0s\n",
      "[########################################] | 100% Completed |  7.6s\n",
      "hamming\n",
      "[########################################] | 100% Completed | 16.3s\n",
      "[########################################] | 100% Completed | 17.6s\n",
      "[########################################] | 100% Completed | 16.1s\n",
      "[########################################] | 100% Completed |  6.3s\n",
      "[########################################] | 100% Completed |  6.5s\n",
      "[########################################] | 100% Completed |  6.1s\n",
      "hamming_norm\n",
      "[########################################] | 100% Completed | 16.6s\n",
      "[########################################] | 100% Completed | 15.8s\n",
      "[########################################] | 100% Completed | 16.3s\n",
      "[########################################] | 100% Completed |  6.4s\n",
      "[########################################] | 100% Completed |  5.8s\n",
      "[########################################] | 100% Completed |  5.8s\n",
      "levenshtein\n",
      "[########################################] | 100% Completed | 13.2s\n",
      "[########################################] | 100% Completed | 15.8s\n",
      "[########################################] | 100% Completed | 13.3s\n",
      "[########################################] | 100% Completed |  5.2s\n",
      "[########################################] | 100% Completed |  5.3s\n",
      "[########################################] | 100% Completed |  5.3s\n",
      "levenshtein_norm\n",
      "[########################################] | 100% Completed | 13.9s\n",
      "[########################################] | 100% Completed | 14.8s\n",
      "[########################################] | 100% Completed | 16.5s\n",
      "[########################################] | 100% Completed |  5.8s\n",
      "[########################################] | 100% Completed |  6.4s\n",
      "[########################################] | 100% Completed |  5.7s\n",
      "damerau_levenshtein\n",
      "[########################################] | 100% Completed | 15.5s\n",
      "[########################################] | 100% Completed | 15.6s\n",
      "[########################################] | 100% Completed | 15.8s\n",
      "[########################################] | 100% Completed |  6.3s\n",
      "[########################################] | 100% Completed |  5.7s\n",
      "[########################################] | 100% Completed |  5.5s\n",
      "jaro_winkler\n",
      "[########################################] | 100% Completed | 18.4s\n",
      "[########################################] | 100% Completed | 16.9s\n",
      "[########################################] | 100% Completed | 19.5s\n",
      "[########################################] | 100% Completed |  6.4s\n",
      "[########################################] | 100% Completed |  6.8s\n",
      "[########################################] | 100% Completed |  6.2s\n",
      "strcmp95\n",
      "[########################################] | 100% Completed | 39.0s\n",
      "[########################################] | 100% Completed | 38.7s\n",
      "[########################################] | 100% Completed | 37.3s\n",
      "[########################################] | 100% Completed | 15.7s\n",
      "[########################################] | 100% Completed | 16.2s\n",
      "[########################################] | 100% Completed | 15.2s\n",
      "tanimoto\n",
      "[########################################] | 100% Completed | 29.0s\n",
      "[########################################] | 100% Completed | 28.8s\n",
      "[########################################] | 100% Completed | 27.7s\n",
      "[########################################] | 100% Completed | 11.0s\n",
      "[########################################] | 100% Completed | 10.9s\n",
      "[########################################] | 100% Completed | 11.5s\n",
      "monge_elkan\n",
      "[########################################] | 100% Completed |  5min 56.4s\n",
      "[########################################] | 100% Completed |  6min 38.7s\n",
      "[########################################] | 100% Completed |  6min 31.0s\n",
      "[########################################] | 100% Completed |  2min 10.4s\n",
      "[########################################] | 100% Completed |  2min 13.7s\n",
      "[########################################] | 100% Completed |  2min  9.5s\n",
      "lcsseq\n",
      "[########################################] | 100% Completed |  1min 58.1s\n",
      "[########################################] | 100% Completed |  2min  3.3s\n",
      "[########################################] | 100% Completed |  1min 57.3s\n",
      "[########################################] | 100% Completed | 40.8s\n",
      "[########################################] | 100% Completed | 37.4s\n",
      "[########################################] | 100% Completed | 38.1s\n",
      "lcsstr\n",
      "[########################################] | 100% Completed | 23.7s\n",
      "[########################################] | 100% Completed | 23.7s\n",
      "[########################################] | 100% Completed | 25.8s\n",
      "[########################################] | 100% Completed |  7.9s\n",
      "[########################################] | 100% Completed |  8.0s\n",
      "[########################################] | 100% Completed |  8.7s\n",
      "needleman_wunsch\n",
      "[########################################] | 100% Completed |  5min  5.1s\n",
      "[########################################] | 100% Completed |  4min 55.7s\n",
      "[########################################] | 100% Completed |  5min 13.5s\n",
      "[########################################] | 100% Completed |  1min 38.4s\n",
      "[########################################] | 100% Completed |  1min 37.8s\n",
      "[########################################] | 100% Completed |  1min 41.1s\n",
      "needleman_wunsch_norm\n",
      "[########################################] | 100% Completed |  5min 28.6s\n",
      "[########################################] | 100% Completed |  5min  7.1s\n",
      "[########################################] | 100% Completed |  5min 47.2s\n",
      "[########################################] | 100% Completed |  1min 39.5s\n",
      "[########################################] | 100% Completed |  1min 40.8s\n",
      "[########################################] | 100% Completed |  1min 42.5s\n",
      "gotoh\n",
      "[########################################] | 100% Completed | 13min 18.2s\n",
      "[########################################] | 100% Completed | 12min 56.7s\n",
      "[########################################] | 100% Completed | 13min 15.0s\n",
      "[########################################] | 100% Completed |  4min 25.8s\n",
      "[########################################] | 100% Completed |  4min 15.7s\n",
      "[########################################] | 100% Completed |  4min 13.7s\n",
      "smith_waterman\n",
      "[########################################] | 100% Completed |  5min 48.7s\n",
      "[########################################] | 100% Completed |  5min 24.6s\n",
      "[########################################] | 100% Completed |  5min 39.7s\n",
      "[########################################] | 100% Completed |  1min 53.9s\n",
      "[########################################] | 100% Completed |  1min 54.9s\n",
      "[########################################] | 100% Completed |  1min 54.6s\n",
      "smith_waterman_norm\n",
      "[########################################] | 100% Completed | 45.8s\n",
      "[########################################] | 100% Completed | 45.6s\n",
      "[########################################] | 100% Completed | 47.1s\n",
      "[########################################] | 100% Completed | 17.7s\n",
      "[########################################] | 100% Completed | 16.0s\n",
      "[########################################] | 100% Completed | 15.5s\n",
      "ratcliff_obershelp\n",
      "[########################################] | 100% Completed | 29.2s\n",
      "[########################################] | 100% Completed | 27.2s\n",
      "[########################################] | 100% Completed | 28.1s\n",
      "[########################################] | 100% Completed | 10.5s\n",
      "[########################################] | 100% Completed |  9.7s\n",
      "[########################################] | 100% Completed | 10.8s\n",
      "cosine\n",
      "[########################################] | 100% Completed | 31.5s\n",
      "[########################################] | 100% Completed | 31.9s\n",
      "[########################################] | 100% Completed | 31.4s\n",
      "[########################################] | 100% Completed | 11.8s\n",
      "[########################################] | 100% Completed | 11.6s\n",
      "[########################################] | 100% Completed | 10.3s\n",
      "jaccard\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 24.9s\n",
      "[########################################] | 100% Completed | 24.8s\n",
      "[########################################] | 100% Completed | 24.6s\n",
      "[########################################] | 100% Completed |  8.8s\n",
      "[########################################] | 100% Completed |  9.8s\n",
      "[########################################] | 100% Completed |  9.6s\n",
      "Wall time: 2h 53min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for name, method in zip(td_names, td_methods):\n",
    "    print(name)\n",
    "    train[name] = train_ddf.apply(td_distance_count, axis=1, args=(method, name), meta=(name, 'float32'))\n",
    "    test[name] = test_ddf.apply(td_distance_count, axis=1, args=(method, name), meta=(name, 'float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio\n",
      "[########################################] | 100% Completed | 13.2s\n",
      "[########################################] | 100% Completed | 13.4s\n",
      "[########################################] | 100% Completed | 13.2s\n",
      "[########################################] | 100% Completed |  5.6s\n",
      "[########################################] | 100% Completed |  4.6s\n",
      "[########################################] | 100% Completed |  4.4s\n",
      "partial_ratio\n",
      "[########################################] | 100% Completed | 19.6s\n",
      "[########################################] | 100% Completed | 20.9s\n",
      "[########################################] | 100% Completed | 21.2s\n",
      "[########################################] | 100% Completed |  7.0s\n",
      "[########################################] | 100% Completed |  6.6s\n",
      "[########################################] | 100% Completed |  6.9s\n",
      "token_sort_ratio\n",
      "[########################################] | 100% Completed | 19.1s\n",
      "[########################################] | 100% Completed | 17.7s\n",
      "[########################################] | 100% Completed | 18.2s\n",
      "[########################################] | 100% Completed |  7.1s\n",
      "[########################################] | 100% Completed |  6.8s\n",
      "[########################################] | 100% Completed |  6.6s\n",
      "token_set_ratio\n",
      "[########################################] | 100% Completed | 22.3s\n",
      "[########################################] | 100% Completed | 22.3s\n",
      "[########################################] | 100% Completed | 21.9s\n",
      "[########################################] | 100% Completed |  8.6s\n",
      "[########################################] | 100% Completed |  8.3s\n",
      "[########################################] | 100% Completed |  8.4s\n",
      "Wall time: 5min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for name, method in zip(fuzz_names, fuzz_methods):\n",
    "    print(name)\n",
    "    train[name] = train_ddf.apply(fuzz_distance_count, axis=1, args=(method, name), meta=(name, 'float32'))\n",
    "    test[name] = test_ddf.apply(fuzz_distance_count, axis=1, args=(method, name), meta=(name, 'float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_with_features.csv')\n",
    "test.to_csv('test_with_features.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
